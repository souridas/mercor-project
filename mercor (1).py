e# -*- coding: utf-8 -*-
"""mercor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CvZr01UJw70CL2t29s3dDk5oEdw-mtsn
"""

print("importing libraries")
import requests
import re
import os
import numpy as np
import pandas as pd
import shutil
import torch
import base64
import ast

"""**Algorithm to calculate the technical complexity of a code**"""

class AlgorithmicVisitor(ast.NodeVisitor):
    def __init__(self):
        self.algorithmic_count = 0

    def visit_For(self, node):
        self.algorithmic_count += 1
        self.generic_visit(node)

    def visit_While(self, node):
        self.algorithmic_count += 1
        self.generic_visit(node)

def is_module_level_function(node):
    visitor = FunctionVisitor()
    visitor.visit(node)
    return visitor.is_module_level

def calculate_complexity(code):
    complexity_scores = {
        'code_structure': 0,
        'readability': 0,
        'dependencies': 0,
        'control_flow': 0,
        'data_structures': 0,
        'error_handling': 0,
        'modularity': 0,
        'performance': 0,
        'testing_documentation': 0,
        'algorithmic': 0
    }

    tree = ast.parse(code)

    # Analyze code structure
    complexity_scores['code_structure'] = len(tree.body)  # Number of top-level statements

    # Evaluate code readability
    comments = ast.get_docstring(tree) or ''
    readability_score = len(comments.split('\n')) + 1
    complexity_scores['readability'] = readability_score

    # Identify code dependencies
    import_count = sum(isinstance(node, ast.Import) or isinstance(node, ast.ImportFrom) for node in tree.body)
    complexity_scores['dependencies'] = import_count

    # Analyze control flow
    control_flow_count = sum(isinstance(node, (ast.If, ast.For, ast.While)) for node in ast.walk(tree))
    complexity_scores['control_flow'] = control_flow_count

    # Evaluate data structures and algorithms
    data_structure_count = sum(isinstance(node, ast.ClassDef) for node in ast.walk(tree))
    algorithmic_visitor = AlgorithmicVisitor()
    algorithmic_visitor.visit(tree)
    algorithmic_count = algorithmic_visitor.algorithmic_count
    complexity_scores['data_structures'] = data_structure_count
    complexity_scores['algorithmic'] = algorithmic_count

    # Consider error handling
    try_except_count = sum(isinstance(node, ast.Try) for node in ast.walk(tree))
    exception_count = sum(isinstance(node, ast.Raise) for node in ast.walk(tree))
    complexity_scores['error_handling'] = try_except_count + exception_count

    # Assess code modularity
    function_count = sum(isinstance(node, ast.FunctionDef) for node in ast.walk(tree))
    class_count = sum(isinstance(node, ast.ClassDef) for node in ast.walk(tree))
    complexity_scores['modularity'] = function_count + class_count

    # Consider performance considerations
    performance_related_count = 0
    for node in ast.walk(tree):
        if isinstance(node, ast.For):
            loop_targets = node.iter
            if isinstance(loop_targets, ast.Call) and loop_targets.func.id == 'range':
                performance_related_count += 1
        elif isinstance(node, ast.FunctionDef):
            func_body = node.body
            if len(func_body) > 0 and isinstance(func_body[0], ast.For):
                performance_related_count += 1
    complexity_scores['performance'] = performance_related_count

    # Evaluate testing and documentation
    docstring_present = bool(ast.get_docstring(tree))
    test_function_count = sum(
        isinstance(node, ast.FunctionDef) and node.name.startswith('test_') and is_module_level_function(node)
        for node in ast.walk(tree)
    )
    complexity_scores['testing_documentation'] = int(docstring_present) + test_function_count

    # Assign complexity scores

    # Assign weightage for each complexity factor
    weightage = {
        'code_structure': .1,
        'readability': .05,
        'dependencies': .1,
        'control_flow': .1,
        'data_structures': 0.3,
        'error_handling': .05,
        'modularity': .05,
        'performance': .1,
        'testing_documentation': .05,
        'algorithmic': .1
    }

    # Calculate complexity rating for each factor by multiplying the score with the weightage
    for factor, score in complexity_scores.items():
        complexity_scores[factor] = score * weightage[factor]

    # Calculate overall complexity rating
    overall_complexity = sum(complexity_scores.values())

    return overall_complexity,complexity_scores

"""### Fetching user repo"""

def fetch_user_repo(url):
    
    response = requests.get(url)

    #success
    if response.status_code == 200:
        repositories = response.json()
        return repositories
    #failed
    else:
        return None

"""### Function to get code from the repo"""

def get_code_from_github(repo_url):
    # Construct the GitHub API URL for retrieving the repository contents
    contents_url = f"{repo_url}/contents"

    # Send a GET request to retrieve the repository contents
    response = requests.get(contents_url)

    if response.status_code == 200:
        # Extract the file paths for the code files matching the specified formats
        files = response.json()

        code_files = []
        for file in files:
            file_path = file["path"]
            if any(file_path.endswith(format) for format in [".py", ".ipynb", ".cpp", ".c", ".java", ".r"]):
                code_files.append(file_path)

        if len(code_files) > 0:
            # Concatenate the code from all the code files
            code = ""
            for file_path in code_files:
                raw_url = f"{repo_url}/contents/{file_path}"
                raw_response = requests.get(raw_url)

                if raw_response.status_code == 200:
                    file_content = raw_response.json()["content"]
                    code += base64.b64decode(file_content).decode("utf-8")
                else:
                    # Print an error message if the request failed
                    print(f"Failed to fetch code from GitHub. Status code: {raw_response.status_code}")

            return code
        else:
            print("No code files found in the repository.")
    else:
        # Print an error message if the request failed
        print(f"Failed to fetch repository contents from GitHub. Status code: {response.status_code}")

    return None

"""### Complex code function"""

def most_complex(repository):

 max_score=0
 max_url=''
 max_complexity={}
 for i in range(len(repository)):

  #fetching all the codes from the repo
  code= get_code_from_github(repositories[i]["url"])

  if code is None:
    continue

  else:

    overall_score, complexity_scores= calculate_complexity(code)


    if overall_score>= max_score:

      max_score= overall_score
      max_url= repositories[i]["url"]
      max_complexity= complexity_scores

 print(f"{max_url} is the most complex repository. It has a technical complexity score of {max_score}. And please refer to the following metrics, which were considered for making this decision: \n {max_complexity}" )

"""### User input"""


url = input("Please enter your github url: ")
repositories= fetch_user_repo(url)

most_complex(repositories)

